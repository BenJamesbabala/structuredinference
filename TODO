1) check that a simple template can be run [Done]
-create load dataset [Done]
-create train.py that loads and runs the dataset [Done]
-create sh file that calls train. [Done]
-Made corrections to DKF to fix L/LR/R issue [Done]

Remarks: Uri has tested this section. it runs for him. [Done]

q2) check that synthetic + polyphonic has been merged
-compile check <- checking against all options for polyphonic & synthetic  [Done]
-create sh files [Done]
    -create files for different options [Done] 
-do the same for synthetic use create experiment to create the necessary sh files [Done]

q3) Create READMEs in each directory [Done]

q3) Reproducing all the results  

1) Synthetic experiments 
2) Polyphonic


Additional TODO
---------------
For the polyphonic experiments, look into
TODO: This includes doing a ****sperate**** run with the *** fixed *** NADE
TODO: At the end of the training script, create a small snippet to estimate the lower bound at test time w/ 1000 samples from the recognition distribution
TODO: remember that for some of the larger NADE models, due to memory requirements, we have to use smaller models
Keep this in mind when creating the sh scripts
This should take ~24 hours. 

Create a file that takes in all the files created and creates the tables that are necessary/used

ipynb/ -> make sure the ipython notebook creates the synthetic plots as in the paper

Aaaaand you're done
--------------------------------------

Paper for arxiv

Edits to paper -> talk about the use of prior add in acknowledgements 
Clean up grammer and make small edits to cealn up notation etc. 
